# AI-Driving-Car 프로젝트 문서
https://github.com/maramsumanth/AI-Driving-Car

## 프로젝트 개요

AI-Driving-Car는 초음파 센서와 머신러닝 알고리즘을 활용한 자율주행 자동차 프로젝트입니다. 이 프로젝트는 환경을 감지하고 인간의 입력 없이 움직일 수 있는 자율주행차 구현을 목표로 합니다.

### 주요 특징
- **센서 기반 환경 감지**: 3개의 초음파 센서(전방, 좌측, 우측)를 사용하여 장애물 거리 측정
- **머신러닝 기반 의사결정**: Random Forest Classifier를 사용한 주행 명령 생성
- **라즈베리파이 기반**: 임베디드 시스템을 활용한 실시간 제어
- **높은 정확도**: 93%의 모델 정확도 달성

## 하드웨어 요구사항

### 필수 구성품
| 구성품 | 수량 | 용도 |
|--------|------|------|
| Raspberry Pi | 1개 | 메인 컨트롤러 |
| L298N Motor Driver | 1개 | 모터 제어 |
| Bread Board (Small) | 1개 | 회로 연결 |
| LIPO Battery | 1개 | 주 전원 공급 |
| Chassis | 1개 | 차체 프레임 |
| Power Bank | 1개 | 보조 전원 |
| Wheels | 2개 | 구동부 |
| Motors | 2개 | 동력원 |
| Ultrasonic Sensors | 3개 | 거리 측정 |
| PS3 Controller | 1개 | 데이터 수집용 |
| Jumper Wires | 필요량 | 연결선 |

### 하드웨어 구성 설명

#### 1. 라즈베리파이
- 프로젝트의 두뇌 역할을 하는 메인 컨트롤러
- 센서 데이터 처리 및 머신러닝 모델 실행
- 모터 제어 신호 생성

#### 2. 초음파 센서 (3개)
- **전방 센서**: 정면 장애물 감지
- **좌측 센서**: 왼쪽 장애물 감지  
- **우측 센서**: 오른쪽 장애물 감지
- 동작 원리: 초음파를 발사하고 반사되어 돌아오는 시간을 측정하여 거리 계산

#### 3. L298N 모터 드라이버
- 라즈베리파이와 모터 사이의 인터페이스 역할
- 듀얼 H-브리지 구조로 2개 모터 동시 제어 가능
- 전압 범위: 5V ~ 35V
- 최대 전류: 2A (연속), 3A (피크)

## 소프트웨어 구성

### 개발 환경
- **플랫폼**: Raspberry Pi OS (Linux)
- **프로그래밍 언어**: Python
- **머신러닝 프레임워크**: scikit-learn
- **주요 라이브러리**: 
  - RPi.GPIO (하드웨어 제어)
  - pandas (데이터 처리)
  - sklearn (머신러닝)

### 핵심 알고리즘: Random Forest Classifier

Random Forest는 여러 개의 의사결정 트리를 결합한 앙상블 학습 방법입니다.

**장점:**
- 높은 예측 정확도
- 과적합 방지
- 특성 중요도 분석 가능
- 노이즈에 강인함

**본 프로젝트에서의 활용:**
- 입력: 3개 센서의 거리 값 (Sensor1, Sensor2, Sensor3)
- 출력: 주행 명령 (Forward/Left/Right/Backward)
- 달성 정확도: 93%

## 데이터 수집 및 모델 훈련

### 1. 데이터 수집 프로세스

#### 수집 환경
- 다양한 미로 구조에서 데이터 수집
- PS3 컨트롤러를 사용한 수동 조작
- Arduino를 활용한 센서 데이터 기록

#### 데이터 형식
```
Command, Sensor1, Sensor2, Sensor3
```
- **Command**: Forward, Left, Right, Backward
- **Sensor1, Sensor2, Sensor3**: 각 센서의 거리 측정값 (cm)

#### 데이터 전처리
- Stop 명령과 해당 센서 데이터 필터링 제거
- 센서 데이터와 명령 데이터 분리
- 훈련용 형식으로 변환

### 2. 모델 훈련 과정

1. **데이터 로딩**: 텍스트 파일에서 센서 데이터와 명령 데이터 분리
2. **특성 공학**: 3개 센서 값을 입력 특성으로 사용
3. **모델 선택**: Random Forest Classifier 선택
4. **하이퍼파라미터 튜닝**: 트리 개수, 깊이 등 최적화
5. **교차 검증**: 모델 성능 검증
6. **최종 모델 저장**: 훈련된 모델을 파일로 저장

## 설치 및 실행 방법

### 1. 저장소 클론
```bash
git clone https://github.com/maramsumanth/AI-Driving-Car.git
cd AI-Driving-Car/
```

### 2. 의존성 설치
```bash
pip install -r requirements.txt
```
주요 라이브러리:
- numpy
- pandas  
- scikit-learn
- RPi.GPIO

### 3. 하드웨어 연결
1. 라즈베리파이에 초음파 센서 3개 연결
2. L298N 모터 드라이버를 통해 모터 연결
3. 전원 연결 (LIPO 배터리, 파워뱅크)
4. 모든 연결선 점검

### 4. 실행
```bash
python finalcode.py
```

### 5. Linux 환경에서 원격 실행
라즈베리파이와 노트북이 같은 WiFi 네트워크에 연결된 경우:
```bash
ssh username@ipaddress
```

## 기술적 세부사항

### 센서 데이터 처리
- 초음파 센서는 음파의 반사 시간을 측정하여 거리 계산
- 측정 범위: 일반적으로 2cm ~ 400cm
- 정확도: ±3mm
- 측정 각도: 약 15도

### 모터 제어
- PWM 신호를 사용한 속도 제어
- 방향 제어: 전진, 후진, 좌회전, 우회전
- L298N을 통한 안전한 전류 공급

### 실시간 처리
- 센서 데이터 읽기 → 전처리 → 모델 예측 → 모터 제어
- 처리 주기: 약 100ms (10Hz)
- 지연 시간 최소화를 위한 코드 최적화

## 성능 및 결과

### 모델 성능
- **정확도**: 93%
- **알고리즘**: Random Forest Classifier
- **특성 수**: 3개 (각 센서별 거리값)
- **클래스 수**: 4개 (Forward, Left, Right, Backward)

### 실제 주행 성능
- 다양한 미로 환경에서 테스트 완료
- 장애물 회피 성공률 높음
- 실시간 의사결정 가능

## 확장 가능성

### 하드웨어 확장
- 카메라 센서 추가로 시각 정보 활용
- GPS 모듈 추가로 위치 정보 활용
- IMU 센서로 자세 정보 획득

### 소프트웨어 개선
- 딥러닝 모델 적용 (CNN, RNN)
- 강화학습을 통한 자율 학습
- 실시간 지도 생성 및 경로 계획

### 응용 분야
- 실내 자율주행 로봇
- 물류 자동화 시스템
- 교육용 자율주행 플랫폼

## 참고 자료 및 관련 기술

### 자율주행 핵심 기술

#### 1. 센서 융합
현대 자율주행차는 다양한 센서를 조합하여 사용합니다:
- **카메라**: 신호등, 표지판 인식
- **라이다**: 정밀한 3D 환경 매핑
- **레이더**: 장거리 물체 감지
- **초음파**: 근거리 장애물 감지

#### 2. 머신러닝 알고리즘
- **Random Forest**: 안정적이고 해석 가능한 모델
- **Deep Learning**: 복잡한 패턴 학습
- **강화학습**: 환경과의 상호작용을 통한 학습

### 프로젝트 한계점
- 초음파 센서만 사용으로 인한 제한적 환경 인식
- 실내 환경에서의 테스트로 제한됨
- 날씨나 조명 변화에 대한 고려 부족

### 개선 방향
- 멀티모달 센서 융합
- 실외 환경 테스트
- 더 복잡한 주행 상황 대응

## 결론

이 AI-Driving-Car 프로젝트는 초음파 센서와 머신러닝을 활용한 기본적인 자율주행 시스템의 구현 사례입니다. 93%의 높은 정확도를 달성하여 센서 기반 자율주행의 가능성을 보여주었으며, 교육용 및 연구용 플랫폼으로서의 가치가 높습니다.

라즈베리파이와 같은 저가의 임베디드 시스템으로도 충분한 성능의 자율주행 시스템을 구축할 수 있음을 증명하였으며, 향후 더 복잡한 자율주행 시스템 개발의 기초가 될 수 있습니다.

---

**프로젝트 저장소**: https://github.com/maramsumanth/AI-Driving-Car
**라이선스**: 오픈소스 (MIT License)
**기여자**: maramsumanth 외 4명
